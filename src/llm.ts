import { Ollama } from "@langchain/community/llms/ollama";

import path, { dirname } from "path";
import fs from "fs-extra";
import { fileURLToPath } from "url";
import { BedrockModelAwsKey, OpenAIModel } from "./app/type.js";
import { PromptTemplate } from "@langchain/core/prompts";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const configPath = path.join(__dirname, 'config.json');
import { BedrockChat } from "@langchain/community/chat_models/bedrock";
import { ChatOpenAI } from "@langchain/openai";
import { parentChildSeparator } from "./splitters/json.js";

const JSON_TEMPLATE = `
- You should not change the keys and only translate the values.
- You should not change JSON object structure and only translate the values.
- You should not change the JSON structure.
- You should not combine similar set of keys into one.
- You should not remove ${parentChildSeparator} from the string or from the JSON object keys.
- You should also change values of the arrays. You should not change the key and order of the array if there is nested array.
- Every JSON object key is very important, you should not not miss any key.
- The translated text should add closing curly brackets to nested object if it is missed.
- While translating you should not change the case of the keys. The keys are case sensitive. You should keep the keys in the same case as they are in the text input.
- Make sure the translated text is valid JSON. If it is not valid JSON, it will fail to parse.
- The translated content is directly sent to JSON.parse() function. You should make sure to return only valid JSON data or it will failed to parse.
- The JSON data is coming in chunks. The relationship between the chunks is maintained by the ${parentChildSeparator} in the keys.
- Each JSON nested object is unique and does not match with its parent object or siblings. Do not merge the nested object with the parent object or any any assumption on the schema of the JSON object.
- If you see any string with ${parentChildSeparator} then this is nested key. This entire key should not be altered or deleted. Only the value should be translated. The nested key is useful to get the JSON data back.
- Return the response into between \`\`\`{fileFormat}\n result \n\`\`\` without result keyword. Don't forget to add {fileFormat} marker between the {fileFormat} response. The response should only content translated text and nothing else.
- Don't use "ï¼Œ", use comma "," instead.
`

const MDX_TEMPLATE = `
- The header chunk is in between "---" lines. You should not change keys of header chunk and only translate the values.
- If the chunk is not starting with "---", then it is not header chunk, it is plain markdown chunk. You should change everything in the chunk and keeps the markdown syntax same.
- You should not remove heading h1 #, h2 ##, h3 ###, h4 ####, h5 #####, h6 ###### from the text or any other markdown syntax
- You should not remove the code blocks or any other syntax of markdown file
- You should not add any additional notes or comments in the markdown file.
- The result response should be in between <markdwon> and </markdown> tags. Do not change the internal content of the markdown file except translation.
`

const getTranslateTemplate = (fileFormat: string, lastFailedInstruction: string = "") => {
	let additionalInstruction = "";
	if (fileFormat === "json") {
		additionalInstruction = JSON_TEMPLATE;
	} else if (fileFormat === "mdx") {
		additionalInstruction = MDX_TEMPLATE;
	}
	return `
- You are expert in language translations. Translate the following sentence to {destLang}
- You should keep the file format {fileFormat} same.
- The translated text will be directly written to the file.
- The translated text should not worry about the perfect translation.
- The input text is coming as a chunk of text and it will be coming in the same format in the output. Don't add anything apart from the translation to avoid wrong message interpretation.
${additionalInstruction}
- You should not break the unique words into parts and translate e.g. NextGenAIKit -> Next Gen AI Kit is wrong, it should be NextGenAIKit.
- The translated content will be send to end user without human intervention. You should not include any line which end user can think that this content is generated by the AI e.g. Here is the translation of the given text from English to or similar kind of messages.
- You should not ask for any feedback and should not include any remarks.
- You should not add any Note or Warning: messages to the translation.
- You should not add any introductory or explanatory or warning messages in the response. This will fail further processing.
- You should return only translated message without any additional messages generated by you. It could be Note: or Warning: or general message.
- You should not add any disclaimers or specific types of messages appended to the response.

${lastFailedInstruction ? `This translation was failed last time and the root cause was: ${lastFailedInstruction}` : ""}

Original Text Content:
{text}
`;
}

function removeMarkdownTags(text: string): string {
	// This regex matches <markdown> tags and their content, including nested tags
	// It looks for the <markdown> opening tag, any content (non-greedy), followed by the closing </markdown> tag
	const markdownRegex = /<markdown>/g;
	const closingRegex = /<\/markdown>/g;

	// Replace all occurrences of the <markdown> tags and their content with an empty string
	return text.replace(markdownRegex, '').replace(closingRegex, '');
}


function extractAndParseJSONFromText(text: string) {
	// Define start and end markers for the JSON content
	const startMarker = '```json';
	const endMarker = '```';

	// Attempt to find the start and end of the JSON content based on the markers
	let startIndex = text.indexOf(startMarker);
	let endIndex = text.indexOf(endMarker, startIndex + startMarker.length);

	let jsonString;

	if (startIndex !== -1 && endIndex !== -1) {

		// Adjust startIndex to skip the marker itself
		startIndex += startMarker.length;
		// Extract the JSON string within markers
		jsonString = text.substring(startIndex, endIndex).trim();
	} else {
		// If markers not found, consider the entire text as potential JSON data
		jsonString = text.trim();
	}

	// Attempt to parse the JSON string
	try {
		const jsonData = JSON.parse(jsonString);
		return jsonData;
	} catch (error: any) {
		console.log("JSON data", text, jsonString)
		throw new Error("Failed to parse JSON. Please make sure result is a valid JSON object and this will be in between ```json\n {result} \n``` without result keyword.");
	}
}


function removeTranslationNotes(content: string) {
	const regex1 = /Here is the translation \w.+/gi; // remove the full like
	const regex2 = /Note: \w.+/gi; // remove the full like
	const regex3 = /Sure, \w.+/gi; // remove the full like
	const regex4 = /^.*Translation: \w.+/;
	return content.replace(regex1, "").replace(regex2, "").replace(regex3, "").replace(regex4, "");
}

export const translate = async (text: string, destLang: string, fileFormat = "text", lastFailedInstruction: string = "") => {
	const configuration = fs.readJsonSync(configPath) as any;
	const model = getLLMModel();
	const prompt = PromptTemplate.fromTemplate(formatPrompt(getTranslateTemplate(fileFormat, lastFailedInstruction)));
	// console.log("Prompt:", prompt)

	// @ts-ignore
	const chain = prompt.pipe(model);
	const response = await chain.invoke({
		destLang,
		text,
		fileFormat,
	}) as any;

	switch (configuration.llm) {
		case "ollama":
			const ollamaContent = removeTranslationNotes(response);
			if (fileFormat === "json") {
				return JSON.stringify(extractAndParseJSONFromText(ollamaContent), null, 2);
			} else if (fileFormat === "mdx") {
				return removeMarkdownTags(ollamaContent);
			}
			return ollamaContent;
		case "bedrock":
			const bedrockContent = removeTranslationNotes(response?.content);
			if (fileFormat === "json") {
				return JSON.stringify(extractAndParseJSONFromText(bedrockContent), null, 2);
			} else if (fileFormat === "mdx") {
				return removeMarkdownTags(bedrockContent);
			}
			return bedrockContent;
		case "open-ai":
			const openAIContent = removeTranslationNotes(response?.content);
			if (fileFormat === "json") {
				return JSON.stringify(extractAndParseJSONFromText(openAIContent), null, 2);
			} else if (fileFormat === "mdx") {
				return removeMarkdownTags(openAIContent);
			}
			return openAIContent;
		default:
			return response;
	}
}


const getLLMModel = () => {
	const configuration = fs.readJsonSync(configPath) as any;
	if (configuration.llm) {
		if (configuration.llm === "ollama") {
			const newConfig = configuration.config as Ollama;
			return new Ollama({
				temperature: 0.1,
				model: newConfig.model,
			});

		}
		if (configuration.llm === "bedrock") {
			const newConfig = configuration.config as BedrockModelAwsKey;
			return new BedrockChat({
				// model: "anthropic.claude-3-sonnet-20240229-v1:0",
				model: newConfig.model, // "anthropic.claude-3-haiku-20240307-v1:0", // "anthropic.claude-3-sonnet-20240229-v1:0
				region: newConfig.region,
				// endpointUrl: "custom.amazonaws.com",
				credentials: {
					accessKeyId: newConfig.accessKey,
					secretAccessKey: newConfig.secretKey,
				},
				// modelKwargs: {
				//   anthropic_version: "bedrock-2023-05-31",
				// },
			});
		}
		if (configuration.llm === "open-ai") {
			const newConfig = configuration.config as OpenAIModel;
			return new ChatOpenAI({
				openAIApiKey: newConfig.apiKey,
				modelName: newConfig.model,
			});
		}

	}
	throw new Error("LLM not found in configuration");
};


export const formatPrompt = (prompt: string) => {
	const configuration = fs.readJsonSync(configPath) as any;
	if (configuration.llm) {
		if (configuration.llm === "bedrock") {
			return `Human: ${prompt}\n Assistant: \n`;
		}
	}
	return prompt;
}

export default getLLMModel;
