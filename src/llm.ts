import { Ollama } from "@langchain/community/llms/ollama";

import path, { dirname } from "path";
import fs from "fs-extra";
import { fileURLToPath } from "url";
import { BedrockModelAwsKey, OpenAIModel } from "./app/type.js";
import { PromptTemplate } from "@langchain/core/prompts";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const configPath = path.join(__dirname, 'config.json');
import { BedrockChat } from "@langchain/community/chat_models/bedrock";
import { ChatOpenAI } from "@langchain/openai";
import { parentChildSeparator } from "./splitters/json.js";

const JSON_TEMPLATE = `
- You should do not change the keys and only translate the values.
- You should not change JSON object structure and only translate the values.
- You should not change the JSON structure.
- You should not combine similar set of keys into one.
- You should not remove ${parentChildSeparator} from the string or from the JSON object keys.
- You should also change values of the arrays. You should not change the key and order of the array if there is nested array.
- The translated text every key is very important, do not miss any key.
- The translated text should add closing curly brackets to nested object if it is missed. This has been missed multiple times.
- The translated text do not change the case of the keys. Keep the keys in the same case as they are in the text input.
- Make sure the translated text is valid JSON. If it is not valid JSON, it will fail to parse.
- The translated content is directly sent to JSON.parse() function. Make sure to return only valid JSON data or it will failed to parse.
- The JSON data is coming in chunks. The relationship between the chunks is maintained by the ${parentChildSeparator} in the keys.
- Each JSON nested object is unique and does not match with its parent object or siblings. Do not merge the nested object with the parent object or any any assumption on the schema of the JSON object.
- If you see any string with ${parentChildSeparator} then this is nested key. This entire key should not be altered or deleted. Only the value should be translated. The nested key is useful to get the JSON data back.
- Don't use "ï¼Œ", use comma "," instead.
`

const MDX_TEMPLATE = `
- For the mdx file format, the header chunk is in between "---" lines. Do not change keys of header chunk and only translate the values.
- For the mdx file format, do not add header chunk if it is not present in the input text chunk.
- For the mdx file format, the translated text should not worry about the perfect translation.
`

const getTranslateTemplate = (fileFormat: string, lastFailedInstruction: string = "") => {
	let additionalInstruction = "";
	if (fileFormat === "json") {
		additionalInstruction = JSON_TEMPLATE;
	} else if (fileFormat === "mdx") {
		additionalInstruction = MDX_TEMPLATE;
	}
	return `
- You are expert in language translations. Translate the following sentence to {destLang}
- Keep the file format {fileFormat} same.
- The translated text will be directly written to the file.
- The translated text should not worry about the perfect translation.
- The input text is coming as a chunk of text and it will be coming in the same format in the output. Don't add anything apart from the translation to avoid wrong message interpretation.
${additionalInstruction}
- The translated text should not worry about the perfect translation.
- The translated text should not break the unique words into parts and translate e.g. NextGenAIKit -> Next Gen AI Kit is wrong, it should be NextGenAIKit.
- The translated content will be send to end user without human intervention. You should not include any line which end user can think that this content is generated by the AI e.g. Here is the translation of the given text from English to or similar kind of messages.
- The translated text should not ask for any feedback and should not include any remarks.
- The translated text should not add any Note or Warning: messages to the translation.
- The translated text should not add any introductory or explanatory or warning messages in the response. This will fail further processing.
- The translated text should return only translated message without any additional messages generated by you. It could be Note: or Warning: or general message.
- You should not add any disclaimers or specific types of messages appended to the response.
- Return the response into between \`\`\`{fileFormat}\n result \n\`\`\` without result keyword. Don't forget to add {fileFormat} marker between the {fileFormat} response. The response should only content translated text and nothing else.

${lastFailedInstruction ? `This translation was failed last time and the root cause was: ${lastFailedInstruction}` : ""}

Original Text Content:
{text}
`;
}

function extractAndParseJSONFromText(text: string) {
	// Define start and end markers for the JSON content
	const startMarker = '```json';
	const endMarker = '```';

	// Attempt to find the start and end of the JSON content based on the markers
	let startIndex = text.indexOf(startMarker);
	let endIndex = text.indexOf(endMarker, startIndex + startMarker.length);

	let jsonString;

	if (startIndex !== -1 && endIndex !== -1) {

		// Adjust startIndex to skip the marker itself
		startIndex += startMarker.length;
		// Extract the JSON string within markers
		jsonString = text.substring(startIndex, endIndex).trim();
	} else {
		// If markers not found, consider the entire text as potential JSON data
		jsonString = text.trim();
	}

	// Attempt to parse the JSON string
	try {
		const jsonData = JSON.parse(jsonString);
		return jsonData;
	} catch (error: any) {
		console.log("JSON data", text, jsonString)
		throw new Error("Failed to parse JSON. Please make sure result is a valid JSON object and this will be in between ```json\n {result} \n``` without result keyword.");
	}
}


export const translate = async (text: string, destLang: string, fileFormat = "text", lastFailedInstruction: string = "") => {
	const configuration = fs.readJsonSync(configPath) as any;
	const model = getLLMModel();
	const prompt = PromptTemplate.fromTemplate(formatPrompt(getTranslateTemplate(fileFormat, lastFailedInstruction)));
	// console.log("Prompt:", prompt)

	// @ts-ignore
	const chain = prompt.pipe(model);
	const response = await chain.invoke({
		destLang,
		text,
		fileFormat,
	}) as any;

	switch (configuration.llm) {
		case "ollama":
			let ollamaContent = response;
			const regex1 = /Here is the translation \w.+/gi; // remove the full like
			const regex2 = /Note: \w.+/gi; // remove the full like
			const regex3 = /Sure, \w.+/gi; // remove the full like
			const regex4 = /^.*Translation: \w.+/;
			if (fileFormat === "json") {
				ollamaContent = ollamaContent.replace(regex1, "").replace(regex2, "").replace(regex3, "").replace(regex4, "");
				return JSON.stringify(extractAndParseJSONFromText(ollamaContent), null, 2);
			}
			return ollamaContent;
		case "bedrock":
			const bedrockContent = response?.content;
			if (fileFormat === "json") {
				return JSON.stringify(extractAndParseJSONFromText(bedrockContent), null, 2);
			}
			return bedrockContent;
		case "open-ai":
			const openAIContent = response?.content;
			if (fileFormat === "json") {
				return JSON.stringify(extractAndParseJSONFromText(openAIContent), null, 2);
			}
			return openAIContent;
		default:
			return response;
	}
}


const getLLMModel = () => {
	const configuration = fs.readJsonSync(configPath) as any;
	if (configuration.llm) {
		if (configuration.llm === "ollama") {
			// @ts-ignore
			const newConfig = configuration.config as Ollama;
			return new Ollama({
				temperature: 0.1,
				model: 'llama2', //newConfig.model,
			});

		}
		if (configuration.llm === "bedrock") {
			const newConfig = configuration.config as BedrockModelAwsKey;
			return new BedrockChat({
				// model: "anthropic.claude-3-sonnet-20240229-v1:0",
				model: newConfig.model, // "anthropic.claude-3-haiku-20240307-v1:0", // "anthropic.claude-3-sonnet-20240229-v1:0
				region: newConfig.region,
				// endpointUrl: "custom.amazonaws.com",
				credentials: {
					accessKeyId: newConfig.accessKey,
					secretAccessKey: newConfig.secretKey,
				},
				// modelKwargs: {
				//   anthropic_version: "bedrock-2023-05-31",
				// },
			});
		}
		if (configuration.llm === "open-ai") {
			const newConfig = configuration.config as OpenAIModel;
			return new ChatOpenAI({
				openAIApiKey: newConfig.apiKey,
				modelName: newConfig.model,
			});
		}

	}
	throw new Error("LLM not found in configuration");
};


export const formatPrompt = (prompt: string) => {
	const configuration = fs.readJsonSync(configPath) as any;
	if (configuration.llm) {
		if (configuration.llm === "bedrock") {
			return `Human: ${prompt}\n Assistant: \n`;
		}
	}
	return prompt;
}

export default getLLMModel;
